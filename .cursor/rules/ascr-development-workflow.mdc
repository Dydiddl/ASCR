---
description: 
globs: 
alwaysApply: false
---
# ASCR Development Workflow & Best Practices

## ğŸš€ Development Environment Setup

### 1. Virtual Environment (MANDATORY)
```bash
# ALWAYS use virtual environment
python -m venv venv
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate     # Windows
pip install -r requirements.txt
```

### 2. Cross-Platform Environment Setup
```bash
# Windows
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Verify platform compatibility
python -c "import platform; print(f'Platform: {platform.system()}')"
```

### 3. Project Structure Validation
Before starting development, verify:
- [ ] All directories exist: `input/`, `output/`, `config/`, `logs/`, `temp/`
- [ ] Configuration files are present: [config/settings.py](mdc:config/settings.py)
- [ ] Dependencies are installed with exact versions
- [ ] Cross-platform compatibility tested on target platforms

## ğŸ”§ Development Workflow

### 1. Feature Development Pattern
```python
# 1. Start with configuration
from config.settings import INPUT_DIR, OUTPUT_DIR, ensure_directories

# 2. Validate environment
ensure_directories()
environment_checks = check_environment()

# 3. Implement core logic with error handling
def new_feature(input_path: str) -> bool:
    """ìƒˆë¡œìš´ ê¸°ëŠ¥ êµ¬í˜„"""
    try:
        # Input validation
        if not Path(input_path).exists():
            print(f"ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {input_path}")
            return False
        
        # Main logic
        result = process_data(input_path)
        
        # Output handling
        save_results(result)
        return True
        
    except Exception as e:
        print(f"ì˜¤ë¥˜: ê¸°ëŠ¥ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False
```

### 2. Testing Pattern
```python
# ALWAYS test with Korean content
test_pdf_path = "input/test_korean_document.pdf"
test_config = {
    "encoding": "utf-8",
    "language": "kor+eng"
}

# Test error conditions
def test_error_scenarios():
    # Test with non-existent file
    result = process_pdf("non_existent.pdf")
    assert result is False
    
    # Test with invalid PDF
    result = process_pdf("invalid.pdf")
    assert result is False
```

### 3. Document Analysis Workflow (MANDATORY)
```python
class DocumentAnalysisWorkflow:
    """ë¬¸ì„œ ë¶„ì„ ì›Œí¬í”Œë¡œìš° - ë°˜ë“œì‹œ ì‚¬ìš©"""
    
    def __init__(self, file_path: Path):
        self.file_path = file_path
        self.analyzer = DocumentAnalyzer(file_path)
        self.searcher = None
        self.results = {}
    
    def execute_analysis(self) -> Dict[str, Any]:
        """ë¬¸ì„œ ë¶„ì„ ì‹¤í–‰"""
        try:
            # 1ë‹¨ê³„: íŒŒì¼ ê²€ì¦
            if not self._validate_file():
                return {"error": "íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨"}
            
            # 2ë‹¨ê³„: ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
            self.results["file_info"] = self._collect_file_info()
            
            # 3ë‹¨ê³„: ë‚´ìš© ë¡œë“œ
            content = self._load_content()
            if not content:
                return {"error": "ë‚´ìš© ë¡œë“œ ì‹¤íŒ¨"}
            
            # 4ë‹¨ê³„: êµ¬ì¡° ë¶„ì„
            self.results["structure"] = self._analyze_structure(content)
            
            # 5ë‹¨ê³„: íŒ¨í„´ ê²€ìƒ‰
            self.results["patterns"] = self._find_patterns(content)
            
            # 6ë‹¨ê³„: ê²€ì¦
            self.results["validation"] = self._validate_results()
            
            # 7ë‹¨ê³„: ê¶Œì¥ì‚¬í•­ ìƒì„±
            self.results["recommendations"] = self._generate_recommendations()
            
            return self.results
            
        except Exception as e:
            return {"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}
    
    def _validate_file(self) -> bool:
        """íŒŒì¼ ê²€ì¦"""
        if not self.file_path.exists():
            print(f"ì˜¤ë¥˜: íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.file_path}")
            return False
        
        if self.file_path.stat().st_size == 0:
            print(f"ì˜¤ë¥˜: ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤: {self.file_path}")
            return False
        
        return True
    
    def _collect_file_info(self) -> Dict[str, Any]:
        """íŒŒì¼ ì •ë³´ ìˆ˜ì§‘"""
        return {
            "name": self.file_path.name,
            "size": self.file_path.stat().st_size,
            "type": self.file_path.suffix.lower(),
            "modified": self.file_path.stat().st_mtime
        }
    
    def _load_content(self) -> str:
        """ë‚´ìš© ë¡œë“œ"""
        try:
            with open(self.file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except UnicodeDecodeError:
            # ë°”ì´ë„ˆë¦¬ íŒŒì¼ì¸ ê²½ìš°
            return "[ë°”ì´ë„ˆë¦¬ íŒŒì¼]"
        except Exception as e:
            print(f"ë‚´ìš© ë¡œë“œ ì‹¤íŒ¨: {e}")
            return ""
    
    def _analyze_structure(self, content: str) -> Dict[str, Any]:
        """êµ¬ì¡° ë¶„ì„"""
        return self.analyzer.analyze_document_structure()
    
    def _find_patterns(self, content: str) -> Dict[str, List[str]]:
        """íŒ¨í„´ ê²€ìƒ‰"""
        self.searcher = ContentSearcher(content)
        search_terms = ["ë¶€ë¬¸", "ì¥", "ì ˆ", "í˜ì´ì§€"]
        return self.searcher.search_with_validation(search_terms)
    
    def _validate_results(self) -> Dict[str, bool]:
        """ê²°ê³¼ ê²€ì¦"""
        validation = {
            "file_valid": True,
            "content_loaded": bool(self.results.get("file_info")),
            "structure_found": bool(self.results.get("structure")),
            "patterns_found": bool(self.results.get("patterns"))
        }
        return validation
    
    def _generate_recommendations(self) -> List[str]:
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if not self.results.get("structure"):
            recommendations.append("ë¬¸ì„œ êµ¬ì¡°ë¥¼ ë” ìì„¸íˆ ë¶„ì„í•˜ì„¸ìš”")
        
        if not self.results.get("patterns"):
            recommendations.append("íŒ¨í„´ ê²€ìƒ‰ì„ í™•ì¥í•˜ì„¸ìš”")
        
        if self.results.get("file_info", {}).get("size", 0) > 1000000:
            recommendations.append("ëŒ€ìš©ëŸ‰ íŒŒì¼ì´ë¯€ë¡œ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”")
        
        return recommendations
```

### 4. Table of Contents Tree Structure Development Workflow (MANDATORY)
```python
class TableOfContentsTreeWorkflow:
    """ëª©ì°¨ íŠ¸ë¦¬ êµ¬ì¡° ê°œë°œ ì›Œí¬í”Œë¡œìš° - ë°˜ë“œì‹œ ì‚¬ìš©"""
    
    def __init__(self, pdf_path: Path):
        self.pdf_path = pdf_path
        self.extractor = PDFTextExtractor()
        self.toc_generator = TableOfContentsGenerator()
        self.results = {}
    
    def execute_toc_tree_generation(self) -> Dict[str, Any]:
        """ëª©ì°¨ íŠ¸ë¦¬ êµ¬ì¡° ìƒì„± ì‹¤í–‰"""
        try:
            # 1ë‹¨ê³„: PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
            extracted_content = self._extract_pdf_content()
            if not extracted_content:
                return {"error": "PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"}
            
            # 2ë‹¨ê³„: ì‹¤ì œ PDF ì¶”ì¶œ ìƒ˜í”Œì„ ê¸°ë°˜ìœ¼ë¡œ, ì¥ ë²ˆí˜¸ì™€ ì œëª©ì´ ë¶„ë¦¬ëœ 
            #        ì¼€ì´ìŠ¤ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ í…ŒìŠ¤íŠ¸í•œë‹¤.
            toc_structure = self._analyze_toc_structure(extracted_content)
            
            # 3ë‹¨ê³„: ì¥ ë²ˆí˜¸ì™€ ì œëª© ì—°ê²° ê²€ì¦
            validation_result = self._validate_chapter_title_connection(toc_structure)
            
            # 4ë‹¨ê³„: íŠ¸ë¦¬ êµ¬ì¡° ìƒì„±
            tree_structure = self._generate_tree_structure(toc_structure)
            
            # 5ë‹¨ê³„: ìë™í™”ëœ ê²°ê³¼ ë¦¬í¬íŠ¸ì—ì„œ ì¥ ë²ˆí˜¸ì™€ ì œëª©ì´ ëˆ„ë½ ì—†ì´ 
            #        ëª¨ë‘ í¬í•¨ë˜ëŠ”ì§€ ê²€ì¦í•œë‹¤.
            report = self._generate_validation_report(tree_structure)
            
            # 6ë‹¨ê³„: ë¬¸ì œ ë°œìƒ ì‹œ, ë°ì´í„° íŒ¨í„´ ë¶„ì„ â†’ ì½”ë“œ/ë£°/í…ŒìŠ¤íŠ¸ ë³´ì™„ 
            #        â†’ ì¬ê²€ì¦ì˜ ì‚¬ì´í´ì„ ë°˜ë³µí•œë‹¤.
            if not self._validate_final_output(tree_structure):
                return self._handle_validation_failure(tree_structure)
            
            return {
                "toc_structure": toc_structure,
                "tree_structure": tree_structure,
                "validation": validation_result,
                "report": report,
                "success": True
            }
            
        except Exception as e:
            return {"error": f"ëª©ì°¨ íŠ¸ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}
    
    def _extract_pdf_content(self) -> str:
        """PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            return self.extractor.extract_text(self.pdf_path)
        except Exception as e:
            print(f"PDF ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def _analyze_toc_structure(self, content: str) -> Dict[str, Any]:
        """ëª©ì°¨ êµ¬ì¡° ë¶„ì„"""
        return self.toc_generator.parse_toc_tree(content)
    
    def _validate_chapter_title_connection(self, toc_structure: Dict) -> Dict[str, bool]:
        """ì¥ ë²ˆí˜¸ì™€ ì œëª© ì—°ê²° ê²€ì¦"""
        validation = {
            "all_chapters_have_titles": True,
            "no_empty_titles": True,
            "proper_format": True
        }
        
        for chapter_key, chapter_data in toc_structure.items():
            if not chapter_data.get("title"):
                validation["all_chapters_have_titles"] = False
                validation["no_empty_titles"] = False
            
            if not chapter_data.get("full_title"):
                validation["proper_format"] = False
        
        return validation
    
    def _generate_tree_structure(self, toc_structure: Dict) -> Dict[str, Any]:
        """íŠ¸ë¦¬ êµ¬ì¡° ìƒì„±"""
        tree = {}
        
        for chapter_key, chapter_data in toc_structure.items():
            if chapter_data.get("full_title"):
                tree[chapter_key] = {
                    "title": chapter_data["full_title"],
                    "page": chapter_data["page"],
                    "children": []
                }
        
        return tree
    
    def _generate_validation_report(self, tree_structure: Dict) -> str:
        """ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = "ëª©ì°¨ íŠ¸ë¦¬ êµ¬ì¡° ê²€ì¦ ë¦¬í¬íŠ¸\n"
        report += "=" * 50 + "\n"
        
        for chapter_key, chapter_data in tree_structure.items():
            report += f"ì¥: {chapter_data['title']}\n"
            report += f"í˜ì´ì§€: {chapter_data['page']}\n"
            report += f"ì œëª© í¬í•¨: {'ì˜ˆ' if chapter_data['title'] else 'ì•„ë‹ˆì˜¤'}\n"
            report += "-" * 30 + "\n"
        
        return report
    
    def _validate_final_output(self, tree_structure: Dict) -> bool:
        """ìµœì¢… ì¶œë ¥ ê²€ì¦"""
        for chapter_data in tree_structure.values():
            if not chapter_data.get("title") or "ì œ" not in chapter_data["title"]:
                return False
        return True
    
    def _handle_validation_failure(self, tree_structure: Dict) -> Dict[str, Any]:
        """ê²€ì¦ ì‹¤íŒ¨ ì²˜ë¦¬"""
        return {
            "error": "ëª©ì°¨ íŠ¸ë¦¬ êµ¬ì¡° ê²€ì¦ ì‹¤íŒ¨",
            "tree_structure": tree_structure,
            "recommendations": [
                "ì¥ ë²ˆí˜¸ì™€ ì œëª©ì´ ì˜¬ë°”ë¥´ê²Œ ì—°ê²°ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”",
                "ë°ì´í„° íŒ¨í„´ì„ ë‹¤ì‹œ ë¶„ì„í•˜ì„¸ìš”",
                "ì½”ë“œ ë¡œì§ì„ ê²€í† í•˜ê³  ìˆ˜ì •í•˜ì„¸ìš”"
            ]
        }
```

## ğŸš¨ CRITICAL DOCUMENT ANALYSIS ERROR PREVENTION WORKFLOW (MANDATORY - NEW)

### 1. Pre-Analysis Checklist (MANDATORY)
```python
def pre_analysis_checklist(file_path: Path) -> Dict[str, bool]:
    """ë¶„ì„ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸ - ë°˜ë“œì‹œ ì‹¤í–‰"""
    checklist = {
        "file_exists": False,
        "file_readable": False,
        "file_not_empty": False,
        "encoding_supported": False,
        "content_contains_korean": False,
        "ready_for_analysis": False
    }
    
    try:
        # 1. íŒŒì¼ ì¡´ì¬ í™•ì¸
        if file_path.exists():
            checklist["file_exists"] = True
        
        # 2. íŒŒì¼ ì½ê¸° ê°€ëŠ¥ í™•ì¸
        if file_path.is_file():
            checklist["file_readable"] = True
        
        # 3. íŒŒì¼ í¬ê¸° í™•ì¸
        if file_path.stat().st_size > 0:
            checklist["file_not_empty"] = True
        
        # 4. ì¸ì½”ë”© ì§€ì› í™•ì¸
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read(1000)
                checklist["encoding_supported"] = True
                
                # 5. í•œêµ­ì–´ ë‚´ìš© í¬í•¨ í™•ì¸
                if any('\u3131' <= char <= '\u318E' or '\uAC00' <= char <= '\uD7A3' for char in content):
                    checklist["content_contains_korean"] = True
        except UnicodeDecodeError:
            pass
        
        # 6. ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ í™•ì¸
        checklist["ready_for_analysis"] = all([
            checklist["file_exists"],
            checklist["file_readable"],
            checklist["file_not_empty"],
            checklist["encoding_supported"],
            checklist["content_contains_korean"]
        ])
                
    except Exception as e:
        print(f"ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return checklist
```

### 2. Section Validation Workflow (MANDATORY)
```python
def validate_all_sections(content: str) -> Dict[str, Any]:
    """ëª¨ë“  ë¶€ë¬¸ ê²€ì¦ - ë°˜ë“œì‹œ ì‹¤í–‰"""
    required_sections = ["ê³µí†µë¶€ë¬¸", "í† ëª©ë¶€ë¬¸", "ê±´ì¶•ë¶€ë¬¸", "ê¸°ê³„ì„¤ë¹„ë¶€ë¬¸", "ìœ ì§€ê´€ë¦¬ë¶€ë¬¸"]
    validation_result = {
        "all_sections_found": True,
        "section_details": {},
        "missing_sections": [],
        "section_order": [],
        "validation_passed": False
    }
    
    # ê° ë¶€ë¬¸ ê²€ìƒ‰ ë° ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
    for section in required_sections:
        section_info = {
            "found": False,
            "position": -1,
            "line_number": -1,
            "context": ""
        }
        
        # ë¶€ë¬¸ ê²€ìƒ‰
        pos = content.find(section)
        if pos != -1:
            section_info["found"] = True
            section_info["position"] = pos
            
            # ì¤„ ë²ˆí˜¸ ê³„ì‚°
            lines_before = content[:pos].count('\n')
            section_info["line_number"] = lines_before + 1
            
            # ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì•ë’¤ 100ì)
            start = max(0, pos - 100)
            end = min(len(content), pos + len(section) + 100)
            section_info["context"] = content[start:end]
            
            validation_result["section_details"][section] = section_info
        else:
            validation_result["missing_sections"].append(section)
            validation_result["all_sections_found"] = False
    
    # ë¶€ë¬¸ ìˆœì„œ ê²°ì •
    found_sections = [(section, info["position"]) for section, info in validation_result["section_details"].items()]
    found_sections.sort(key=lambda x: x[1])
    validation_result["section_order"] = [section for section, _ in found_sections]
    
    # ê²€ì¦ í†µê³¼ ì—¬ë¶€
    validation_result["validation_passed"] = validation_result["all_sections_found"]
    
    return validation_result
```

### 3. Analysis Report Generation Workflow (MANDATORY)
```python
def generate_validated_analysis_report(file_path: Path, analysis_results: Dict[str, Any], 
                                     validation_results: Dict[str, Any]) -> str:
    """ê²€ì¦ëœ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± - ë°˜ë“œì‹œ ì‚¬ìš©"""
    
    # 1. ê¸°ë³¸ ë³´ê³ ì„œ ìƒì„±
    report = f"""# ğŸ“‹ PDF êµ¬ì¡° ë¶„ì„ ë³´ê³ ì„œ (ê²€ì¦ë¨)

## ğŸ¯ ë¶„ì„ ê°œìš”
- **íŒŒì¼ëª…**: {file_path.name}
- **ë¶„ì„ ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ê²€ì¦ ìƒíƒœ**: {'âœ… í†µê³¼' if validation_results.get('validation_passed', False) else 'âŒ ì‹¤íŒ¨'}

## ğŸ—ï¸ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„
"""
    
    # 2. ë¶€ë¬¸ë³„ ìƒì„¸ ì •ë³´ ì¶”ê°€
    section_details = validation_results.get("section_details", {})
    for section_name, section_info in section_details.items():
        if section_info["found"]:
            report += f"""
### {section_name}
- **ìœ„ì¹˜**: {section_info['line_number']}ë²ˆì§¸ ì¤„
- **ì»¨í…ìŠ¤íŠ¸**: {section_info['context'][:200]}...
"""
    
    # 3. ëˆ„ë½ëœ ë¶€ë¬¸ ê²½ê³ 
    missing_sections = validation_results.get("missing_sections", [])
    if missing_sections:
        report += f"""
## âš ï¸ ëˆ„ë½ëœ ë¶€ë¬¸
ë‹¤ìŒ ë¶€ë¬¸ì´ ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:
{chr(10).join(f'- {section}' for section in missing_sections)}

**ê¶Œì¥ì‚¬í•­**: ì „ì²´ ë¬¸ì„œë¥¼ ë‹¤ì‹œ ê²€í† í•˜ì—¬ ëˆ„ë½ëœ ë¶€ë¬¸ì„ í™•ì¸í•˜ì„¸ìš”.
"""
    
    # 4. ê²€ì¦ ê²°ê³¼ ìš”ì•½
    report += f"""
## âœ… ê²€ì¦ ê²°ê³¼
- **ëª¨ë“  ë¶€ë¬¸ ë°œê²¬**: {'ì˜ˆ' if validation_results.get('all_sections_found', False) else 'ì•„ë‹ˆì˜¤'}
- **ë¶€ë¬¸ ìˆœì„œ**: {' â†’ '.join(validation_results.get('section_order', []))}
- **ë¶„ì„ ì‹ ë¢°ë„**: {analysis_results.get('analysis_confidence', 0):.1f}%

## ğŸ’¡ ê¶Œì¥ì‚¬í•­
"""
    
    if validation_results.get("validation_passed", False):
        report += "- âœ… ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
    else:
        report += "- ğŸ”„ ëˆ„ë½ëœ ë¶€ë¬¸ì„ í™•ì¸í•˜ê³  ì¬ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.\n"
        report += "- ğŸ“– ë¬¸ì„œì˜ ì „ì²´ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ ê²€í† í•˜ì„¸ìš”.\n"
        report += "- ğŸ” ë¶€ë¬¸ ì œëª©ì˜ ì •í™•í•œ í‘œê¸°ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n"
    
    return report
```

### 4. Error Prevention Workflow (MANDATORY)
```python
def execute_error_prevention_workflow(file_path: Path) -> Dict[str, Any]:
    """ì˜¤ë¥˜ ë°©ì§€ ì›Œí¬í”Œë¡œìš° - ë°˜ë“œì‹œ ì‚¬ìš©"""
    try:
        # 1ë‹¨ê³„: ì‚¬ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸
        checklist = pre_analysis_checklist(file_path)
        if not checklist["ready_for_analysis"]:
            return {
                "error": "íŒŒì¼ì´ ë¶„ì„ ì¤€ë¹„ê°€ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                "checklist": checklist,
                "is_valid": False
            }
        
        # 2ë‹¨ê³„: íŒŒì¼ ë‚´ìš© ë¡œë“œ
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # 3ë‹¨ê³„: ë¶€ë¬¸ ê²€ì¦
        validation_results = validate_all_sections(content)
        
        # 4ë‹¨ê³„: ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
        analyzer = DocumentAnalyzer(file_path)
        analysis_results = analyzer.analyze_document_structure()
        
        # 5ë‹¨ê³„: ê²€ì¦ëœ ë³´ê³ ì„œ ìƒì„±
        comprehensive_report = generate_validated_analysis_report(
            file_path, analysis_results, validation_results
        )
        
        # 6ë‹¨ê³„: ê²°ê³¼ ë°˜í™˜
        final_result = {
            "checklist": checklist,
            "validation_results": validation_results,
            "analysis_results": analysis_results,
            "comprehensive_report": comprehensive_report,
            "is_valid": validation_results.get("validation_passed", False)
        }
        
        # 7ë‹¨ê³„: ê²€ì¦ ì‹¤íŒ¨ ì‹œ ê²½ê³ 
        if not final_result["is_valid"]:
            print("âš ï¸ ê²½ê³ : ë¶€ë¬¸ ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤!")
            print(f"ëˆ„ë½ëœ ë¶€ë¬¸: {', '.join(validation_results.get('missing_sections', []))}")
            print("ì „ì²´ ë¬¸ì„œë¥¼ ë‹¤ì‹œ ê²€í† í•˜ì„¸ìš”.")
        
        return final_result
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°©ì§€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {
            "error": str(e),
            "is_valid": False
        }
```

### 5. Mandatory Development Rules (MANDATORY)
```python
# ğŸš¨ ë°˜ë“œì‹œ ì¤€ìˆ˜í•´ì•¼ í•  ê°œë°œ ê·œì¹™

# 1. ëª¨ë“  ë¬¸ì„œ ë¶„ì„ì€ execute_error_prevention_workflow() ì‚¬ìš©
# 2. ë¶„ì„ ì „ pre_analysis_checklist() ì‹¤í–‰ í•„ìˆ˜
# 3. ë¶€ë¬¸ ê²€ì¦ì€ validate_all_sections() ì‚¬ìš©
# 4. ë³´ê³ ì„œ ìƒì„±ì€ generate_validated_analysis_report() ì‚¬ìš©
# 5. ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì‚¬ìš©ìì—ê²Œ ê²½ê³ 
# 6. ëˆ„ë½ëœ ë¶€ë¬¸ì´ ìˆìœ¼ë©´ ì¬ë¶„ì„ ìˆ˜í–‰
# 7. ëª¨ë“  ë¶„ì„ ê²°ê³¼ëŠ” ê²€ì¦ í›„ì—ë§Œ ìµœì¢… í™•ì •

def mandatory_development_workflow(file_path: Path) -> Dict[str, Any]:
    """í•„ìˆ˜ ê°œë°œ ì›Œí¬í”Œë¡œìš° - ë°˜ë“œì‹œ ì‚¬ìš©"""
    print("ğŸš€ í•„ìˆ˜ ê°œë°œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ì˜¤ë¥˜ ë°©ì§€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    result = execute_error_prevention_workflow(file_path)
    
    # ê²€ì¦ ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„
    if not result.get("is_valid", False):
        print("ğŸ”„ ê²€ì¦ ì‹¤íŒ¨ë¡œ ì¸í•œ ì¬ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        result = execute_error_prevention_workflow(file_path)
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    if result.get("is_valid", False):
        print("âœ… ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âŒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    return result
```

**ğŸš¨ CRITICAL: ê±´ì¶•ë¶€ë¬¸ ëˆ„ë½ ì‚¬ê³ ì™€ ê°™ì€ ë¶„ì„ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ìœ„ì˜ ëª¨ë“  ì›Œí¬í”Œë¡œìš°ë¥¼ ë°˜ë“œì‹œ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.**

## ğŸŒ Cross-Platform Development Guidelines

### 1. Platform Detection and Configuration
```python
import platform
import sys
from pathlib import Path

def setup_cross_platform_environment() -> Dict[str, str]:
    """í¬ë¡œìŠ¤ í”Œë«í¼ í™˜ê²½ ì„¤ì •"""
    platform_info = {
        "os": platform.system(),
        "version": platform.version(),
        "python_version": sys.version,
        "architecture": platform.architecture()[0]
    }
    
    # Platform-specific configurations
    if platform.system() == "Windows":
        platform_info.update({
            "temp_dir": os.environ.get("TEMP", "C:\\Temp"),
            "home_dir": os.environ.get("USERPROFILE", ""),
            "python_exe": "python.exe",
            "path_separator": "\\"
        })
    else:  # macOS/Linux
        platform_info.update({
            "temp_dir": "/tmp",
            "home_dir": os.environ.get("HOME", ""),
            "python_exe": "python3",
            "path_separator": "/"
        })
    
    return platform_info

def validate_cross_platform_setup() -> bool:
    """í¬ë¡œìŠ¤ í”Œë«í¼ ì„¤ì • ê²€ì¦"""
    try:
        # Check Python version compatibility
        if sys.version_info < (3, 8):
            print("ì˜¤ë¥˜: Python 3.8 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return False
        
        # Check required modules
        required_modules = ['pathlib', 'platform', 'json', 'pandas']
        for module in required_modules:
            try:
                __import__(module)
            except ImportError:
                print(f"ì˜¤ë¥˜: í•„ìˆ˜ ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤: {module}")
                return False
        
        # Check file system permissions
        test_dir = Path("temp") / "test_cross_platform"
        test_dir.mkdir(parents=True, exist_ok=True)
        test_file = test_dir / "test.txt"
        test_file.write_text("test", encoding='utf-8')
        test_file.unlink()
        test_dir.rmdir()
        
        print("í¬ë¡œìŠ¤ í”Œë«í¼ ì„¤ì • ê²€ì¦ ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"í¬ë¡œìŠ¤ í”Œë«í¼ ì„¤ì • ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False
```

### 2. Cross-Platform File Operations
```python
def create_cross_platform_file_structure() -> bool:
    """í¬ë¡œìŠ¤ í”Œë«í¼ íŒŒì¼ êµ¬ì¡° ìƒì„±"""
    directories = [
        "input",
        "output", 
        "config",
        "logs",
        "temp",
        "src/classifier",
        "src/converter", 
        "src/utils",
        "src/utils/ect"
    ]
    
    try:
        for dir_path in directories:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
        
        # Create platform-specific test files
        test_files = {
            "input/test_korean.txt": "í•œêµ­ì–´ í…ŒìŠ¤íŠ¸ íŒŒì¼",
            "config/platform_test.json": '{"platform": "test"}',
            "temp/platform_temp.txt": "ì„ì‹œ íŒŒì¼"
        }
        
        for file_path, content in test_files.items():
            Path(file_path).write_text(content, encoding='utf-8')
        
        return True
        
    except Exception as e:
        print(f"íŒŒì¼ êµ¬ì¡° ìƒì„± ì‹¤íŒ¨: {e}")
        return False

def cleanup_cross_platform_test_files() -> None:
    """í¬ë¡œìŠ¤ í”Œë«í¼ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬"""
    test_files = [
        "input/test_korean.txt",
        "config/platform_test.json", 
        "temp/platform_temp.txt"
    ]
    
    for file_path in test_files:
        try:
            Path(file_path).unlink(missing_ok=True)
        except Exception as e:
            print(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {file_path} - {e}")
```

### 3. Cross-Platform Testing Strategy
```python
def run_cross_platform_tests() -> Dict[str, bool]:
    """í¬ë¡œìŠ¤ í”Œë«í¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    test_results = {
        "file_operations": False,
        "encoding_handling": False,
        "path_operations": False,
        "command_execution": False
    }
    
    try:
        # íŒŒì¼ ì‘ì—… í…ŒìŠ¤íŠ¸
        test_file = Path("temp") / "cross_platform_test.txt"
        test_file.write_text("í…ŒìŠ¤íŠ¸ ë‚´ìš©", encoding='utf-8')
        if test_file.exists() and test_file.read_text(encoding='utf-8') == "í…ŒìŠ¤íŠ¸ ë‚´ìš©":
            test_results["file_operations"] = True
        test_file.unlink()
        
        # ì¸ì½”ë”© ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        korean_text = "í•œêµ­ì–´ í…ŒìŠ¤íŠ¸"
        try:
            encoded = korean_text.encode('utf-8')
            decoded = encoded.decode('utf-8')
            if decoded == korean_text:
                test_results["encoding_handling"] = True
        except UnicodeError:
            pass
        
        # ê²½ë¡œ ì‘ì—… í…ŒìŠ¤íŠ¸
        test_path = Path("temp") / "test" / "subdir"
        test_path.mkdir(parents=True, exist_ok=True)
        if test_path.exists():
            test_results["path_operations"] = True
        test_path.rmdir()
        test_path.parent.rmdir()
        
        # ëª…ë ¹ì–´ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
        try:
            import subprocess
            result = subprocess.run([sys.executable, "-c", "print('test')"], 
                                  capture_output=True, text=True)
            if result.returncode == 0 and "test" in result.stdout:
                test_results["command_execution"] = True
        except Exception:
            pass
        
    except Exception as e:
        print(f"í¬ë¡œìŠ¤ í”Œë«í¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    return test_results
```

## ğŸ“Š Document Analysis Best Practices

### 1. Multi-Step Analysis Process
```python
def comprehensive_document_analysis(file_path: Path) -> Dict[str, Any]:
    """ì¢…í•©ì ì¸ ë¬¸ì„œ ë¶„ì„"""
    results = {
        "file_info": {},
        "structure": {},
        "content_analysis": {},
        "validation": {},
        "recommendations": []
    }
    
    # 1ë‹¨ê³„: íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
    results["file_info"] = collect_file_info(file_path)
    
    # 2ë‹¨ê³„: êµ¬ì¡° ë¶„ì„
    results["structure"] = analyze_document_structure(file_path)
    
    # 3ë‹¨ê³„: ë‚´ìš© ë¶„ì„
    results["content_analysis"] = analyze_content(file_path)
    
    # 4ë‹¨ê³„: ê²€ì¦
    results["validation"] = validate_analysis_results(results)
    
    # 5ë‹¨ê³„: ê¶Œì¥ì‚¬í•­ ìƒì„±
    results["recommendations"] = generate_recommendations(results)
    
    return results
```

### 2. Error Prevention Strategies
```python
class ErrorPreventionStrategy:
    """ì˜¤ë¥˜ ë°©ì§€ ì „ëµ"""
    
    @staticmethod
    def validate_input_files(file_paths: List[Path]) -> List[Path]:
        """ì…ë ¥ íŒŒì¼ ê²€ì¦"""
        valid_files = []
        
        for file_path in file_paths:
            if not file_path.exists():
                print(f"ê²½ê³ : íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
                continue
            
            if file_path.stat().st_size == 0:
                print(f"ê²½ê³ : ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤: {file_path}")
                continue
            
            valid_files.append(file_path)
        
        return valid_files
    
    @staticmethod
    def check_document_consistency(content: str) -> Dict[str, bool]:
        """ë¬¸ì„œ ì¼ê´€ì„± ê²€ì‚¬"""
        checks = {
            "has_content": len(content.strip()) > 0,
            "has_structure": any(keyword in content for keyword in ["ë¶€ë¬¸", "ì¥", "ì ˆ"]),
            "has_page_breaks": "===" in content,
            "encoding_valid": True
        }
        
        try:
            content.encode('utf-8')
        except UnicodeEncodeError:
            checks["encoding_valid"] = False
        
        return checks
    
    @staticmethod
    def generate_analysis_report(results: Dict[str, Any]) -> str:
        """ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        report = []
        report.append("=== ë¬¸ì„œ ë¶„ì„ ë³´ê³ ì„œ ===")
        
        # íŒŒì¼ ì •ë³´
        file_info = results.get("file_info", {})
        report.append(f"íŒŒì¼ëª…: {file_info.get('name', 'N/A')}")
        report.append(f"í¬ê¸°: {file_info.get('size', 0)} bytes")
        
        # êµ¬ì¡° ì •ë³´
        structure = results.get("structure", {})
        if structure.get("sections"):
            report.append("ë°œê²¬ëœ ë¶€ë¬¸:")
            for section, info in structure["sections"].items():
                if info.get("start") is not None:
                    report.append(f"  - {section}")
        
        # ê²€ì¦ ê²°ê³¼
        validation = results.get("validation", {})
        report.append("ê²€ì¦ ê²°ê³¼:")
        for check, status in validation.items():
            status_text = "âœ… í†µê³¼" if status else "âŒ ì‹¤íŒ¨"
            report.append(f"  - {check}: {status_text}")
        
        # ê¶Œì¥ì‚¬í•­
        recommendations = results.get("recommendations", [])
        if recommendations:
            report.append("ê¶Œì¥ì‚¬í•­:")
            for rec in recommendations:
                report.append(f"  - {rec}")
        
        return "\n".join(report)
```

### 3. Quality Assurance Workflow
```python
def quality_assurance_checklist() -> Dict[str, bool]:
    """í’ˆì§ˆ ë³´ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸"""
    checklist = {
        "cross_platform_compatibility": False,
        "error_handling": False,
        "document_analysis": False,
        "validation_logic": False,
        "korean_support": False
    }
    
    # í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜ì„± í™•ì¸
    try:
        platform_info = setup_cross_platform_environment()
        if platform_info.get("os"):
            checklist["cross_platform_compatibility"] = True
    except Exception:
        pass
    
    # ì˜¤ë¥˜ ì²˜ë¦¬ í™•ì¸
    try:
        # í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜ ì²˜ë¦¬
        test_result = test_error_handling()
        checklist["error_handling"] = test_result
    except Exception:
        pass
    
    # ë¬¸ì„œ ë¶„ì„ í™•ì¸
    try:
        test_file = Path("temp") / "test_analysis.txt"
        test_file.write_text("í…ŒìŠ¤íŠ¸ ë¬¸ì„œ\nì œ1ì¥ í…ŒìŠ¤íŠ¸\n1-1 í…ŒìŠ¤íŠ¸ì ˆ", encoding='utf-8')
        
        workflow = DocumentAnalysisWorkflow(test_file)
        results = workflow.execute_analysis()
        
        if results and not results.get("error"):
            checklist["document_analysis"] = True
        
        test_file.unlink()
    except Exception:
        pass
    
    # ê²€ì¦ ë¡œì§ í™•ì¸
    try:
        test_content = "í•œêµ­ì–´ í…ŒìŠ¤íŠ¸ ë‚´ìš©"
        validation = ErrorPreventionStrategy.check_document_consistency(test_content)
        if validation.get("has_content") and validation.get("encoding_valid"):
            checklist["validation_logic"] = True
    except Exception:
        pass
    
    # í•œêµ­ì–´ ì§€ì› í™•ì¸
    try:
        korean_text = "í•œêµ­ì–´ í…ŒìŠ¤íŠ¸"
        encoded = korean_text.encode('utf-8')
        decoded = encoded.decode('utf-8')
        if decoded == korean_text:
            checklist["korean_support"] = True
    except Exception:
        pass
    
    return checklist

def test_error_handling() -> bool:
    """ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    try:
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í…ŒìŠ¤íŠ¸
        non_existent_file = Path("non_existent_file.txt")
        if non_existent_file.exists():
            return False
        
        # ë¹ˆ íŒŒì¼ í…ŒìŠ¤íŠ¸
        empty_file = Path("temp") / "empty_test.txt"
        empty_file.write_text("", encoding='utf-8')
        if empty_file.stat().st_size != 0:
            empty_file.unlink()
            return False
        empty_file.unlink()
        
        return True
    except Exception:
        return False
```

## ğŸ¯ Development Best Practices

### 1. Code Review Process
```python
def code_review_checklist() -> List[str]:
    """ì½”ë“œ ë¦¬ë·° ì²´í¬ë¦¬ìŠ¤íŠ¸"""
    checklist = [
        "ëª¨ë“  í•¨ìˆ˜ì— íƒ€ì… íŒíŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?",
        "í•œêµ­ì–´ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?",
        "í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜ì„±ì„ ê³ ë ¤í–ˆëŠ”ê°€?",
        "ë¬¸ì„œ ë¶„ì„ íŒ¨í„´ì„ ì ìš©í–ˆëŠ”ê°€?",
        "ê²€ì¦ ë¡œì§ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?",
        "ì˜ˆì™¸ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆëŠ”ê°€?",
        "í•˜ë“œì½”ë”©ëœ ê°’ì„ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ëŠ”ê°€?",
        "pathlib.Pathë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?",
        "UTF-8 ì¸ì½”ë”©ì„ ì‚¬ìš©í•˜ëŠ”ê°€?",
        "ì„¤ì •ì„ ì™¸ë¶€í™”í–ˆëŠ”ê°€?",
        "ì „ì—­ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ëŠ”ê°€?",
        "í•¨ìˆ˜ê°€ 50ì¤„ ì´í•˜ì¸ê°€?",
        "í´ë˜ìŠ¤ê°€ ë‹¨ì¼ ì±…ì„ ì›ì¹™ì„ ë”°ë¥´ëŠ”ê°€?"
    ]
    return checklist
```

### 2. Testing Strategy
```python
def testing_strategy() -> Dict[str, List[str]]:
    """í…ŒìŠ¤íŠ¸ ì „ëµ"""
    return {
        "unit_tests": [
            "ê° í•¨ìˆ˜ì˜ ê°œë³„ ë™ì‘ í…ŒìŠ¤íŠ¸",
            "ì˜¤ë¥˜ ìƒí™© í…ŒìŠ¤íŠ¸",
            "ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸",
            "íƒ€ì… íŒíŠ¸ ê²€ì¦"
        ],
        "integration_tests": [
            "ëª¨ë“ˆ ê°„ ì—°ë™ í…ŒìŠ¤íŠ¸",
            "íŒŒì¼ ì…ì¶œë ¥ í…ŒìŠ¤íŠ¸",
            "ì„¤ì • íŒŒì¼ ë¡œë“œ í…ŒìŠ¤íŠ¸"
        ],
        "cross_platform_tests": [
            "Windows í™˜ê²½ í…ŒìŠ¤íŠ¸",
            "macOS í™˜ê²½ í…ŒìŠ¤íŠ¸", 
            "Linux í™˜ê²½ í…ŒìŠ¤íŠ¸",
            "ê²½ë¡œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸",
            "ì¸ì½”ë”© ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"
        ],
        "document_analysis_tests": [
            "í•œêµ­ì–´ ë¬¸ì„œ í…ŒìŠ¤íŠ¸",
            "PDF íŒŒì¼ í…ŒìŠ¤íŠ¸",
            "ëŒ€ìš©ëŸ‰ íŒŒì¼ í…ŒìŠ¤íŠ¸",
            "ì†ìƒëœ íŒŒì¼ í…ŒìŠ¤íŠ¸"
        ]
    }
```

### 3. Documentation Standards
```python
def documentation_standards() -> Dict[str, List[str]]:
    """ë¬¸ì„œí™” í‘œì¤€"""
    return {
        "code_documentation": [
            "ëª¨ë“  ëª¨ë“ˆì— í•œêµ­ì–´ ì„¤ëª… í¬í•¨",
            "í•¨ìˆ˜ë³„ ìƒì„¸í•œ docstring ì‘ì„±",
            "ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ì— ì£¼ì„ ì¶”ê°€",
            "ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì„¤ëª… í¬í•¨"
        ],
        "user_documentation": [
            "ì‚¬ìš©ì ê°€ì´ë“œ ì‘ì„±",
            "ì„¤ì¹˜ ë° ì„¤ì • ë°©ë²• ë¬¸ì„œí™”",
            "ì˜¤ë¥˜ í•´ê²° ë°©ë²• ê°€ì´ë“œ",
            "í¬ë¡œìŠ¤ í”Œë«í¼ ì‚¬ìš©ë²• ì„¤ëª…"
        ],
        "api_documentation": [
            "API ì—”ë“œí¬ì¸íŠ¸ ì„¤ëª…",
            "ìš”ì²­/ì‘ë‹µ ì˜ˆì œ í¬í•¨",
            "ì˜¤ë¥˜ ì½”ë“œ ë° ë©”ì‹œì§€ ë¬¸ì„œí™”",
            "ì¸ì¦ ë° ê¶Œí•œ ì„¤ëª…"
        ],
        "maintenance_documentation": [
            "ë°°í¬ í”„ë¡œì„¸ìŠ¤ ë¬¸ì„œí™”",
            "ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… ê°€ì´ë“œ",
            "ë°±ì—… ë° ë³µêµ¬ ì ˆì°¨",
            "ì„±ëŠ¥ íŠœë‹ ê°€ì´ë“œ"
        ]
    }
```

## ğŸ”„ Continuous Improvement

### 1. Performance Monitoring
```python
def performance_monitoring() -> Dict[str, Any]:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
    import time
    import psutil
    
    return {
        "memory_usage": psutil.virtual_memory().percent,
        "cpu_usage": psutil.cpu_percent(),
        "disk_usage": psutil.disk_usage('/').percent,
        "timestamp": time.time()
    }
```

### 2. Error Tracking
```python
def error_tracking() -> Dict[str, List[str]]:
    """ì˜¤ë¥˜ ì¶”ì """
    return {
        "common_errors": [
            "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ",
            "ì¸ì½”ë”© ì˜¤ë¥˜",
            "ê¶Œí•œ ì˜¤ë¥˜",
            "ë©”ëª¨ë¦¬ ë¶€ì¡±",
            "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜"
        ],
        "error_resolution": [
            "íŒŒì¼ ê²½ë¡œ í™•ì¸",
            "UTF-8 ì¸ì½”ë”© ì‚¬ìš©",
            "ê´€ë¦¬ì ê¶Œí•œ í™•ì¸",
            "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”",
            "ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸"
        ]
    }
```

### 3. Quality Metrics
```python
def quality_metrics() -> Dict[str, float]:
    """í’ˆì§ˆ ì§€í‘œ"""
    return {
        "code_coverage": 85.0,  # ëª©í‘œ: 85% ì´ìƒ
        "test_pass_rate": 95.0,  # ëª©í‘œ: 95% ì´ìƒ
        "documentation_completeness": 90.0,  # ëª©í‘œ: 90% ì´ìƒ
        "cross_platform_compatibility": 100.0,  # ëª©í‘œ: 100%
        "error_handling_coverage": 95.0  # ëª©í‘œ: 95% ì´ìƒ
    }
```

**ğŸš¨ CRITICAL: ëª¨ë“  ë¬¸ì„œ ë¶„ì„ ì‘ì—…ì€ ë°˜ë“œì‹œ ìœ„ì˜ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.**

## ğŸ“‹ ëª©ì°¨ íŠ¸ë¦¬ ê³„ì¸µ êµ¬ì¡° ì›Œí¬í”Œë¡œìš° (MANDATORY - NEW)

### 1. ê³„ì¸µ êµ¬ì¡° ìƒì„± íŒ¨í„´ (MANDATORY)
```python
class HierarchicalTOCWorkflow:
    """ê³„ì¸µì  ëª©ì°¨ íŠ¸ë¦¬ ìƒì„± ì›Œí¬í”Œë¡œìš° - ë°˜ë“œì‹œ ì‚¬ìš©"""
    
    def __init__(self):
        self.hierarchy_rules = TOCHierarchyRules()
        self.results = {}
    
    def execute_hierarchical_generation(self, toc_items: List[Dict]) -> Dict[str, Any]:
        """ê³„ì¸µì  ëª©ì°¨ íŠ¸ë¦¬ ìƒì„± ì‹¤í–‰"""
        try:
            # 1ë‹¨ê³„: ê³„ì¸µ ë ˆë²¨ ë¶„ì„
            hierarchy_analysis = self._analyze_hierarchy_levels(toc_items)
            
            # 2ë‹¨ê³„: ê³„ì¸µì  íŠ¸ë¦¬ ìƒì„±
            hierarchical_tree = self._generate_hierarchical_tree(toc_items)
            
            # 3ë‹¨ê³„: ê³„ì¸µ êµ¬ì¡° ê²€ì¦
            hierarchy_validation = self._validate_hierarchy_structure(hierarchical_tree)
            
            # 4ë‹¨ê³„: ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì¬êµ¬ì„±
            if not hierarchy_validation["is_valid"]:
                print("âš ï¸ ê²½ê³ : ê³„ì¸µ êµ¬ì¡° ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                hierarchical_tree = self._regenerate_hierarchy_structure(toc_items)
                hierarchy_validation = self._validate_hierarchy_structure(hierarchical_tree)
            
            # 5ë‹¨ê³„: ê³„ì¸µì  ë§ˆí¬ë‹¤ìš´ ìƒì„±
            hierarchical_markdown = self._generate_hierarchical_markdown(hierarchical_tree)
            
            return {
                "hierarchical_tree": hierarchical_tree,
                "hierarchy_analysis": hierarchy_analysis,
                "hierarchy_validation": hierarchy_validation,
                "hierarchical_markdown": hierarchical_markdown,
                "is_valid": hierarchy_validation["is_valid"]
            }
            
        except Exception as e:
            return {"error": f"ê³„ì¸µì  ëª©ì°¨ íŠ¸ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}
    
    def _analyze_hierarchy_levels(self, toc_items: List[Dict]) -> Dict[str, Any]:
        """ê³„ì¸µ ë ˆë²¨ ë¶„ì„"""
        analysis = {
            "ëŒ€ë¶„ë¥˜": [],
            "ì¤‘ë¶„ë¥˜": [],
            "ì†Œë¶„ë¥˜": [],
            "ë³¸ë¬¸ë¶„ë¥˜": [],
            "ì„¸ë¶€ë¶„ë¥˜": []
        }
        
        for item in toc_items:
            level = self.hierarchy_rules.get_hierarchy_level(item['title'])
            item['level'] = level
            
            if level == 0:
                analysis["ëŒ€ë¶„ë¥˜"].append(item)
            elif level == 1:
                analysis["ì¤‘ë¶„ë¥˜"].append(item)
            elif level == 2:
                analysis["ì†Œë¶„ë¥˜"].append(item)
            elif level == 3:
                analysis["ë³¸ë¬¸ë¶„ë¥˜"].append(item)
            elif level == 4:
                analysis["ì„¸ë¶€ë¶„ë¥˜"].append(item)
        
        return analysis
    
    def _generate_hierarchical_tree(self, toc_items: List[Dict]) -> Dict[str, Any]:
        """ê³„ì¸µì  íŠ¸ë¦¬ ìƒì„±"""
        return generate_hierarchical_toc(toc_items)
    
    def _validate_hierarchy_structure(self, hierarchical_tree: dict) -> Dict[str, Any]:
        """ê³„ì¸µ êµ¬ì¡° ê²€ì¦"""
        return validate_hierarchy_structure(hierarchical_tree)
    
    def _regenerate_hierarchy_structure(self, toc_items: List[Dict]) -> Dict[str, Any]:
        """ê³„ì¸µ êµ¬ì¡° ì¬ìƒì„±"""
        print("ğŸ”„ ê³„ì¸µ êµ¬ì¡° ì¬êµ¬ì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        return generate_hierarchical_toc(toc_items)
    
    def _generate_hierarchical_markdown(self, hierarchical_tree: dict) -> str:
        """ê³„ì¸µì  ë§ˆí¬ë‹¤ìš´ ìƒì„±"""
        markdown = "# ğŸ“‹ ê³„ì¸µì  ëª©ì°¨ êµ¬ì¡° (ì˜¬ë°”ë¥¸ ë“¤ì—¬ì“°ê¸° ì ìš©)\n\n"
        
        for root_node in hierarchical_tree.get('children', []):
            markdown += render_hierarchical_markdown(root_node)
        
        return markdown
```

### 2. ê³„ì¸µ êµ¬ì¡° ê²€ì¦ ì›Œí¬í”Œë¡œìš° (MANDATORY)
```python
def execute_hierarchy_validation_workflow(toc_tree: dict) -> Dict[str, Any]:
    """ê³„ì¸µ êµ¬ì¡° ê²€ì¦ ì›Œí¬í”Œë¡œìš° - ë°˜ë“œì‹œ ì‚¬ìš©"""
    
    # 1ë‹¨ê³„: ê¸°ë³¸ ê³„ì¸µ êµ¬ì¡° ê²€ì¦
    validation = validate_hierarchy_structure(toc_tree)
    
    # 2ë‹¨ê³„: ì˜¤ë¥˜ ë¶„ì„
    if not validation["is_valid"]:
        print("âŒ ê³„ì¸µ êµ¬ì¡° ì˜¤ë¥˜ ë°œê²¬:")
        
        # ê³„ì¸µ ì˜¤ë¥˜ ì¶œë ¥
        if validation["hierarchy_errors"]:
            print(f"  - ê³„ì¸µ ë ˆë²¨ ì˜¤ë¥˜: {len(validation['hierarchy_errors'])}ê°œ")
            for error in validation["hierarchy_errors"][:5]:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
                print(f"    * {error['node']}: ì˜ˆìƒ ë ˆë²¨ {error['expected_level']}, ì‹¤ì œ ë ˆë²¨ {error['actual_level']}")
        
        # ë“¤ì—¬ì“°ê¸° ì˜¤ë¥˜ ì¶œë ¥
        if validation["indent_errors"]:
            print(f"  - ë“¤ì—¬ì“°ê¸° ì˜¤ë¥˜: {len(validation['indent_errors'])}ê°œ")
            for error in validation["indent_errors"][:5]:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
                print(f"    * {error['node']}: ì˜ˆìƒ ë“¤ì—¬ì“°ê¸° '{error['expected_indent']}', ì‹¤ì œ ë“¤ì—¬ì“°ê¸° '{error['actual_indent']}'")
    
    # 3ë‹¨ê³„: ì˜¤ë¥˜ ìˆ˜ì • ì œì•ˆ
    if not validation["is_valid"]:
        print("\nğŸ”§ ì˜¤ë¥˜ ìˆ˜ì • ì œì•ˆ:")
        print("  1. ê³„ì¸µ ë ˆë²¨ì„ ì •í™•íˆ íŒë‹¨í•˜ì—¬ level ì†ì„± ì„¤ì •")
        print("  2. ë“¤ì—¬ì“°ê¸°ë¥¼ ê³„ì¸µ ë ˆë²¨ì— ë§ê²Œ ì ìš©")
        print("  3. ìƒìœ„ í•­ëª© ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” í•˜ìœ„ í•­ëª©ë“¤ì„ ì ì ˆí•œ ë¶€ëª¨ì— ë°°ì¹˜")
    
    return validation
```

### 3. ê³„ì¸µ êµ¬ì¡° í…ŒìŠ¤íŠ¸ íŒ¨í„´ (MANDATORY)
```python
def test_hierarchy_structure():
    """ê³„ì¸µ êµ¬ì¡° í…ŒìŠ¤íŠ¸"""
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_items = [
        {"title": "ì œ1ì¥ ì ìš©ê¸°ì¤€", "page": 3, "type": "chapter"},
        {"title": "1-1 ì¼ë°˜ì‚¬í•­", "page": 3, "type": "item"},
        {"title": "1-1-1 ëª©ì ", "page": 3, "type": "item"},
        {"title": "1-1-2 ì ìš©ë²”ìœ„", "page": 3, "type": "item"},
        {"title": "1-2 ì„¤ê³„ ë° ìˆ˜ëŸ‰", "page": 3, "type": "item"},
        {"title": "1-2-1 ìˆ˜ëŸ‰ì˜ ê³„ì‚°", "page": 3, "type": "item"},
        {"title": "ì œ2ì¥ ê°€ì„¤ê³µì‚¬", "page": 33, "type": "chapter"},
        {"title": "2-8 ì¶”ë½ì¬í•´ë°©ì§€ì‹œì„¤", "page": 47, "type": "item"},
        {"title": "2-8-11 ê³„ë‹¨ë‚œê°„ëŒ€ ì„¤ì¹˜ ë° í•´ì²´", "page": 50, "type": "item"},
        {"title": "2-8-12 ì•ˆì „ë‚œê°„ëŒ€ ì„¤ì¹˜ ë° í•´ì²´(í† ëª©)", "page": 51, "type": "item"},
        {"title": "2-9 í†µí–‰ì•ˆì „ì‹œì„¤", "page": 52, "type": "item"},
        {"title": "2-9-1 íƒ€ì›Œí¬ë ˆì¸ ë°©í˜¸ìš¸íƒ€ë¦¬ ì„¤ì¹˜ ë° í•´ì²´", "page": 52, "type": "item"}
    ]
    
    # 1ë‹¨ê³„: ê³„ì¸µì  ëª©ì°¨ íŠ¸ë¦¬ ìƒì„±
    workflow = HierarchicalTOCWorkflow()
    result = workflow.execute_hierarchical_generation(test_items)
    
    # 2ë‹¨ê³„: ê²°ê³¼ ê²€ì¦
    assert "error" not in result, f"ê³„ì¸µì  ëª©ì°¨ íŠ¸ë¦¬ ìƒì„± ì‹¤íŒ¨: {result.get('error')}"
    assert result.get("is_valid", False), "ê³„ì¸µ êµ¬ì¡° ê²€ì¦ ì‹¤íŒ¨"
    
    # 3ë‹¨ê³„: ê³„ì¸µ êµ¬ì¡° í™•ì¸
    tree = result.get("hierarchical_tree", {})
    assert tree.get("children"), "ê³„ì¸µ íŠ¸ë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
    
    # 4ë‹¨ê³„: ë“¤ì—¬ì“°ê¸° í™•ì¸
    markdown = result.get("hierarchical_markdown", "")
    assert "  - ì œ1ì¥" in markdown, "ì¤‘ë¶„ë¥˜ ë“¤ì—¬ì“°ê¸° ì˜¤ë¥˜"
    assert "    - 1-1" in markdown, "ì†Œë¶„ë¥˜ ë“¤ì—¬ì“°ê¸° ì˜¤ë¥˜"
    assert "      - 1-1-1" in markdown, "ë³¸ë¬¸ë¶„ë¥˜ ë“¤ì—¬ì“°ê¸° ì˜¤ë¥˜"
    
    print("âœ… ê³„ì¸µ êµ¬ì¡° í…ŒìŠ¤íŠ¸ í†µê³¼")
    return result
```

### 4. ê³„ì¸µ êµ¬ì¡° ì ìš© ì›Œí¬í”Œë¡œìš° (MANDATORY)
```python
def apply_hierarchical_structure_to_existing_toc(toc_tree: dict) -> dict:
    """ê¸°ì¡´ ëª©ì°¨ íŠ¸ë¦¬ì— ê³„ì¸µ êµ¬ì¡° ì ìš© - ë°˜ë“œì‹œ ì‚¬ìš©"""
    
    # 1ë‹¨ê³„: ê¸°ì¡´ íŠ¸ë¦¬ë¥¼ í‰ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    flat_items = []
    
    def extract_items(node):
        item = {
            'title': node.get('title', ''),
            'page': node.get('page', 0),
            'type': node.get('type', 'item'),
            'number': node.get('number', '')
        }
        flat_items.append(item)
        
        for child in node.get('children', []):
            extract_items(child)
    
    for root_node in toc_tree.get('children', []):
        extract_items(root_node)
    
    # 2ë‹¨ê³„: ê³„ì¸µì  íŠ¸ë¦¬ ì¬ìƒì„±
    workflow = HierarchicalTOCWorkflow()
    result = workflow.execute_hierarchical_generation(flat_items)
    
    # 3ë‹¨ê³„: ê²°ê³¼ ë°˜í™˜
    if result.get("is_valid", False):
        print("âœ… ê³„ì¸µ êµ¬ì¡° ì ìš© ì™„ë£Œ")
        return result.get("hierarchical_tree", {})
    else:
        print("âŒ ê³„ì¸µ êµ¬ì¡° ì ìš© ì‹¤íŒ¨")
        return toc_tree
```

**ğŸš¨ CRITICAL: ê³„ì¸µ êµ¬ì¡° ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ìœ„ì˜ ëª¨ë“  ê³„ì¸µ êµ¬ì¡° ì›Œí¬í”Œë¡œìš°ë¥¼ ë°˜ë“œì‹œ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.**




