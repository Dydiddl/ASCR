#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PDF í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° - í˜ì´ì§€ë³„, ì¤„ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)
ë¬¸ì„œ ë¶„ì„ íŒ¨í„´ê³¼ ê²€ì¦ ë¡œì§ì„ í¬í•¨í•œ ì²´ê³„ì  ì ‘ê·¼
"""

import fitz  # PyMuPDF
from pathlib import Path
from typing import List, Dict, Optional, Any
from datetime import datetime
import re

# ì„¤ì • ëª¨ë“ˆ import
try:
    from config.settings import INPUT_DIR, OUTPUT_DIR, ensure_directories
except ImportError:
    INPUT_DIR = Path("input")
    OUTPUT_DIR = Path("output")
    
    def ensure_directories():
        INPUT_DIR.mkdir(exist_ok=True)
        OUTPUT_DIR.mkdir(exist_ok=True)

class DocumentAnalyzer:
    """ë¬¸ì„œ ë¶„ì„ í´ë˜ìŠ¤ - ë°˜ë“œì‹œ ì‚¬ìš©"""
    
    def __init__(self, file_path: Path):
        self.file_path = file_path
        self.content = ""
        self.structure = {}
        
    def analyze_document_structure(self) -> Dict[str, Any]:
        """ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ - ì²´ê³„ì  ì ‘ê·¼ í•„ìˆ˜"""
        try:
            # 1. íŒŒì¼ íƒ€ì… ë° í¬ê¸° í™•ì¸
            file_info = self._get_file_info()
            
            # 2. ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 1000ì)
            preview = self._get_content_preview()
            
            # 3. êµ¬ì¡°ì  íŒ¨í„´ ê²€ìƒ‰
            patterns = self._find_structural_patterns()
            
            # 4. ë¶€ë¬¸/ì¥/ì ˆ êµ¬ë¶„ ë¶„ì„
            sections = self._analyze_sections()
            
            # 5. ê²€ì¦ ë° ê²°ê³¼ ë°˜í™˜
            return self._validate_and_return(file_info, preview, patterns, sections)
            
        except Exception as e:
            print(f"ë¬¸ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}
    
    def _get_file_info(self) -> Dict[str, Any]:
        """íŒŒì¼ ì •ë³´ ìˆ˜ì§‘"""
        return {
            "name": self.file_path.name,
            "size": self.file_path.stat().st_size,
            "type": self.file_path.suffix.lower(),
            "exists": self.file_path.exists()
        }
    
    def _get_content_preview(self) -> str:
        """ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°"""
        try:
            with open(self.file_path, 'r', encoding='utf-8') as f:
                return f.read(1000)
        except UnicodeDecodeError:
            # ë°”ì´ë„ˆë¦¬ íŒŒì¼ì¸ ê²½ìš°
            return "[ë°”ì´ë„ˆë¦¬ íŒŒì¼]"
    
    def _find_structural_patterns(self) -> Dict[str, List[str]]:
        """êµ¬ì¡°ì  íŒ¨í„´ ê²€ìƒ‰"""
        patterns = {
            "ë¶€ë¬¸": [],
            "ì¥": [],
            "ì ˆ": [],
            "í˜ì´ì§€": []
        }
        
        # ì •ê·œì‹ íŒ¨í„´ ì •ì˜
        section_patterns = {
            "ë¶€ë¬¸": r"([ê°€-í£]+ë¶€ë¬¸)",
            "ì¥": r"(ì œ[0-9]+ì¥\s*[ê°€-í£]+)",
            "ì ˆ": r"([0-9]+-[0-9]+[ê°€-í£]*)",
            "í˜ì´ì§€": r"(=== [0-9]+í˜ì´ì§€ ===)"
        }
        
        # íŒ¨í„´ ê²€ìƒ‰
        for pattern_name, pattern in section_patterns.items():
            matches = re.findall(pattern, self.content)
            patterns[pattern_name] = matches
        
        return patterns
    
    def _analyze_sections(self) -> Dict[str, Any]:
        """ë¶€ë¬¸/ì¥/ì ˆ êµ¬ë¶„ ë¶„ì„"""
        sections = {
            "ê³µí†µë¶€ë¬¸": {"start": None, "end": None, "chapters": []},
            "í† ëª©ë¶€ë¬¸": {"start": None, "end": None, "chapters": []},
            "ê±´ì¶•ë¶€ë¬¸": {"start": None, "end": None, "chapters": []},
            "ê¸°ê³„ì„¤ë¹„ë¶€ë¬¸": {"start": None, "end": None, "chapters": []},
            "ìœ ì§€ê´€ë¦¬ë¶€ë¬¸": {"start": None, "end": None, "chapters": []}
        }
        
        # ë¶€ë¬¸ ì‹œì‘ì  ì°¾ê¸°
        for line_num, line in enumerate(self.content.split('\n')):
            for section_name in sections.keys():
                if section_name in line:
                    sections[section_name]["start"] = line_num
                    break
        
        return sections
    
    def _validate_and_return(self, file_info: Dict, preview: str, 
                           patterns: Dict, sections: Dict) -> Dict[str, Any]:
        """ê²€ì¦ ë° ê²°ê³¼ ë°˜í™˜"""
        return {
            "file_info": file_info,
            "preview": preview[:200] + "..." if len(preview) > 200 else preview,
            "patterns": patterns,
            "sections": sections,
            "analysis_confidence": self._calculate_confidence(patterns, sections)
        }
    
    def _calculate_confidence(self, patterns: Dict, sections: Dict) -> float:
        """ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.0
        
        # ë¶€ë¬¸ì´ ë°œê²¬ë˜ë©´ +30%
        if any(sections[section]["start"] is not None for section in sections):
            confidence += 0.3
        
        # ì¥ì´ ë°œê²¬ë˜ë©´ +30%
        if patterns["ì¥"]:
            confidence += 0.3
        
        # ì ˆì´ ë°œê²¬ë˜ë©´ +20%
        if patterns["ì ˆ"]:
            confidence += 0.2
        
        # í˜ì´ì§€ êµ¬ë¶„ì´ ë°œê²¬ë˜ë©´ +20%
        if patterns["í˜ì´ì§€"]:
            confidence += 0.2
        
        return min(confidence, 1.0)

class ContentSearcher:
    """ë‚´ìš© ê²€ìƒ‰ ë° ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self, content: str):
        self.content = content
        self.search_results = {}
    
    def search_with_validation(self, search_terms: List[str]) -> Dict[str, List[Dict]]:
        """ê²€ìƒ‰ì–´ë¡œ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ ê²€ì¦"""
        results = {}
        
        for term in search_terms:
            found_locations = self._find_term_locations(term)
            validated_results = self._validate_search_results(term, found_locations)
            results[term] = validated_results
        
        return results
    
    def _find_term_locations(self, term: str) -> List[Dict]:
        """ìš©ì–´ ìœ„ì¹˜ ì°¾ê¸°"""
        locations = []
        lines = self.content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            if term in line:
                locations.append({
                    "line_number": line_num,
                    "line_content": line,
                    "context": self._get_context(lines, line_num)
                })
        
        return locations
    
    def _get_context(self, lines: List[str], line_num: int, context_size: int = 2) -> List[str]:
        """ì£¼ë³€ ë¬¸ë§¥ ê°€ì ¸ì˜¤ê¸°"""
        start = max(0, line_num - context_size - 1)
        end = min(len(lines), line_num + context_size)
        return lines[start:end]
    
    def _validate_search_results(self, term: str, locations: List[Dict]) -> List[Dict]:
        """ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦"""
        validated = []
        
        for location in locations:
            # ì¤‘ë³µ ì œê±°
            if not any(v["line_number"] == location["line_number"] for v in validated):
                # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
                relevance_score = self._calculate_relevance(term, location["line_content"])
                if relevance_score > 0.5:  # 50% ì´ìƒ ê´€ë ¨ì„±
                    location["relevance_score"] = relevance_score
                    validated.append(location)
        
        return validated
    
    def _calculate_relevance(self, term: str, line_content: str) -> float:
        """ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        if term in line_content:
            # ì •í™•íˆ ì¼ì¹˜í•˜ë©´ ë†’ì€ ì ìˆ˜
            if term == line_content.strip():
                return 1.0
            # ë¶€ë¶„ ì¼ì¹˜í•˜ë©´ ì¤‘ê°„ ì ìˆ˜
            elif term in line_content:
                return 0.8
        return 0.0

class PDFTextExtractor:
    """PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í´ë˜ìŠ¤ (ê°œì„ ëœ ë²„ì „)"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        ensure_directories()
        self.analyzer = None
        self.searcher = None
    
    def extract_text_by_pages(self, pdf_path: Path, output_filename: Optional[str] = None) -> str:
        """
        PDF íŒŒì¼ì—ì„œ í˜ì´ì§€ë³„ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ TXT íŒŒì¼ë¡œ ì €ì¥ (ê°œì„ ëœ ë²„ì „)
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            output_filename: ì¶œë ¥ íŒŒì¼ëª… (ì„ íƒì‚¬í•­)
            
        Returns:
            str: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        try:
            # 1ë‹¨ê³„: íŒŒì¼ ê²€ì¦
            if not self._validate_pdf_file(pdf_path):
                return ""
            
            # 2ë‹¨ê³„: PDF ì •ë³´ ìˆ˜ì§‘
            pdf_info = self.get_pdf_info(pdf_path)
            print(f"=== PDF ì •ë³´ ===")
            print(f"íŒŒì¼ëª…: {pdf_info.get('íŒŒì¼ëª…', 'N/A')}")
            print(f"ì´ í˜ì´ì§€ ìˆ˜: {pdf_info.get('ì´_í˜ì´ì§€_ìˆ˜', 'N/A')}")
            print(f"íŒŒì¼ í¬ê¸°: {pdf_info.get('íŒŒì¼_í¬ê¸°', 'N/A')}")
            print()
            
            # 3ë‹¨ê³„: í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° êµ¬ì¡°í™”
            extracted_content = self._extract_and_structure_text(pdf_path)
            
            # 4ë‹¨ê³„: ë¬¸ì„œ ë¶„ì„
            analysis_results = self._analyze_extracted_content(extracted_content)
            
            # 5ë‹¨ê³„: ì¶œë ¥ íŒŒì¼ëª… ê²°ì •
            if output_filename is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_filename = f"{pdf_path.stem}_extracted_{timestamp}.txt"
            
            output_path = OUTPUT_DIR / output_filename
            
            # 6ë‹¨ê³„: ê²°ê³¼ ì €ì¥
            self._save_extracted_content(output_path, extracted_content, analysis_results)
            
            # 7ë‹¨ê³„: ê²€ì¦ ë° ë³´ê³ ì„œ ìƒì„±
            validation_report = self._generate_validation_report(analysis_results)
            print(validation_report)
            
            return str(output_path)
            
        except Exception as e:
            print(f"ì˜¤ë¥˜: PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return ""
    
    def _validate_pdf_file(self, pdf_path: Path) -> bool:
        """PDF íŒŒì¼ ê²€ì¦"""
        if not pdf_path.exists():
            print(f"ì˜¤ë¥˜: PDF íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pdf_path}")
            return False
        
        if pdf_path.stat().st_size == 0:
            print(f"ì˜¤ë¥˜: PDF íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {pdf_path}")
            return False
        
        if pdf_path.suffix.lower() != '.pdf':
            print(f"ì˜¤ë¥˜: PDF íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {pdf_path}")
            return False
        
        return True
    
    def _extract_and_structure_text(self, pdf_path: Path) -> str:
        """í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° êµ¬ì¡°í™”"""
        try:
            doc = fitz.open(str(pdf_path))
            total_pages = len(doc)
            
            extracted_content = []
            
            print("=== í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘ ===")
            
            for page_num in range(total_pages):
                print(f"í˜ì´ì§€ {page_num + 1}/{total_pages} ì²˜ë¦¬ ì¤‘...")
                
                page = doc.load_page(page_num)
                text = page.get_text()
                
                if text.strip():  # ë¹ˆ í˜ì´ì§€ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ì²˜ë¦¬
                    # í˜ì´ì§€ ì‹œì‘ í‘œì‹œ
                    extracted_content.append(f"=== {page_num + 1}í˜ì´ì§€ ===")
                    
                    # ì¤„ë³„ë¡œ ë²ˆí˜¸ ë§¤ê¸°ê¸°
                    lines = text.strip().split('\n')
                    for line_num, line in enumerate(lines, 1):
                        if line.strip():  # ë¹ˆ ì¤„ ì œì™¸
                            extracted_content.append(f"{line_num}ì¤„: {line}")
                    
                    # í˜ì´ì§€ êµ¬ë¶„ì
                    extracted_content.append("----")
                    extracted_content.append("")  # ë¹ˆ ì¤„ ì¶”ê°€
            
            doc.close()
            
            return '\n'.join(extracted_content)
            
        except Exception as e:
            print(f"ì˜¤ë¥˜: í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return ""
    
    def _analyze_extracted_content(self, content: str) -> Dict[str, Any]:
        """ì¶”ì¶œëœ ë‚´ìš© ë¶„ì„"""
        try:
            # ë¬¸ì„œ ë¶„ì„ê¸° ì´ˆê¸°í™”
            temp_file = Path("temp") / "temp_content.txt"
            temp_file.parent.mkdir(exist_ok=True)
            temp_file.write_text(content, encoding='utf-8')
            
            self.analyzer = DocumentAnalyzer(temp_file)
            self.analyzer.content = content
            
            # êµ¬ì¡° ë¶„ì„
            structure_analysis = self.analyzer.analyze_document_structure()
            
            # ê²€ìƒ‰ ë° ê²€ì¦
            self.searcher = ContentSearcher(content)
            search_results = self.searcher.search_with_validation([
                "ë¶€ë¬¸", "ì¥", "ì ˆ", "í˜ì´ì§€", "ë„ë¡œ", "í•˜ì²œ", "í„°ë„"
            ])
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            temp_file.unlink()
            
            return {
                "structure": structure_analysis,
                "search_results": search_results,
                "content_length": len(content),
                "line_count": len(content.split('\n')),
                "analysis_timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"ì˜¤ë¥˜: ë‚´ìš© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}
    
    def _save_extracted_content(self, output_path: Path, content: str, analysis_results: Dict[str, Any]):
        """ì¶”ì¶œëœ ë‚´ìš© ì €ì¥"""
        try:
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            metadata = self._generate_metadata(analysis_results)
            
            # ì „ì²´ ë‚´ìš© êµ¬ì„±
            full_content = f"""# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼

## ë©”íƒ€ë°ì´í„°
{metadata}

## ì¶”ì¶œëœ ë‚´ìš©
{content}

## ë¶„ì„ ì™„ë£Œ ì‹œê°„
{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
"""
            
            # íŒŒì¼ ì €ì¥
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(full_content)
            
            print(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {output_path}")
            print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {output_path.stat().st_size:,} bytes")
            
        except Exception as e:
            print(f"ì˜¤ë¥˜: íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def _generate_metadata(self, analysis_results: Dict[str, Any]) -> str:
        """ë©”íƒ€ë°ì´í„° ìƒì„±"""
        metadata_lines = []
        
        # ê¸°ë³¸ ì •ë³´
        structure = analysis_results.get("structure", {})
        file_info = structure.get("file_info", {})
        
        metadata_lines.append(f"- íŒŒì¼ëª…: {file_info.get('name', 'N/A')}")
        metadata_lines.append(f"- íŒŒì¼ í¬ê¸°: {file_info.get('size', 0):,} bytes")
        metadata_lines.append(f"- ë‚´ìš© ê¸¸ì´: {analysis_results.get('content_length', 0):,} characters")
        metadata_lines.append(f"- ì´ ì¤„ ìˆ˜: {analysis_results.get('line_count', 0):,} lines")
        
        # ë¶„ì„ ì‹ ë¢°ë„
        confidence = structure.get("analysis_confidence", 0.0)
        metadata_lines.append(f"- ë¶„ì„ ì‹ ë¢°ë„: {confidence:.1%}")
        
        # ë°œê²¬ëœ íŒ¨í„´
        patterns = structure.get("patterns", {})
        for pattern_type, pattern_list in patterns.items():
            if pattern_list:
                metadata_lines.append(f"- ë°œê²¬ëœ {pattern_type}: {len(pattern_list)}ê°œ")
        
        # ê²€ìƒ‰ ê²°ê³¼
        search_results = analysis_results.get("search_results", {})
        for term, results in search_results.items():
            if results:
                metadata_lines.append(f"- '{term}' ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
        
        return '\n'.join(metadata_lines)
    
    def _generate_validation_report(self, analysis_results: Dict[str, Any]) -> str:
        """ê²€ì¦ ë³´ê³ ì„œ ìƒì„±"""
        report_lines = []
        report_lines.append("=== ê²€ì¦ ë³´ê³ ì„œ ===")
        
        # ê¸°ë³¸ ê²€ì¦
        structure = analysis_results.get("structure", {})
        confidence = structure.get("analysis_confidence", 0.0)
        
        if confidence >= 0.8:
            report_lines.append("âœ… ë†’ì€ ì‹ ë¢°ë„ë¡œ ë¶„ì„ ì™„ë£Œ")
        elif confidence >= 0.5:
            report_lines.append("âš ï¸ ì¤‘ê°„ ì‹ ë¢°ë„ë¡œ ë¶„ì„ ì™„ë£Œ")
        else:
            report_lines.append("âŒ ë‚®ì€ ì‹ ë¢°ë„ - ì¶”ê°€ ê²€í†  í•„ìš”")
        
        # íŒ¨í„´ ê²€ì¦
        patterns = structure.get("patterns", {})
        if patterns.get("ë¶€ë¬¸"):
            report_lines.append("âœ… ë¶€ë¬¸ êµ¬ì¡° ë°œê²¬")
        if patterns.get("ì¥"):
            report_lines.append("âœ… ì¥ êµ¬ì¡° ë°œê²¬")
        if patterns.get("ì ˆ"):
            report_lines.append("âœ… ì ˆ êµ¬ì¡° ë°œê²¬")
        if patterns.get("í˜ì´ì§€"):
            report_lines.append("âœ… í˜ì´ì§€ êµ¬ë¶„ ë°œê²¬")
        
        # ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦
        search_results = analysis_results.get("search_results", {})
        for term, results in search_results.items():
            if results:
                report_lines.append(f"âœ… '{term}' ê´€ë ¨ ë‚´ìš© {len(results)}ê°œ ë°œê²¬")
        
        return '\n'.join(report_lines)
    
    def get_pdf_info(self, pdf_path: Path) -> Dict[str, Any]:
        """
        PDF íŒŒì¼ ì •ë³´ ë°˜í™˜
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict[str, Any]: PDF íŒŒì¼ ì •ë³´
        """
        try:
            doc = fitz.open(str(pdf_path))
            
            info = {
                "íŒŒì¼ëª…": pdf_path.name,
                "ì´_í˜ì´ì§€_ìˆ˜": len(doc),
                "íŒŒì¼_í¬ê¸°": f"{pdf_path.stat().st_size:,} bytes",
                "PDF_ë²„ì „": doc.version,
                "ë©”íƒ€ë°ì´í„°": doc.metadata
            }
            
            doc.close()
            return info
            
        except Exception as e:
            print(f"ì˜¤ë¥˜: PDF ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}

class ErrorPreventionStrategy:
    """ì˜¤ë¥˜ ë°©ì§€ ì „ëµ"""
    
    @staticmethod
    def validate_input_files(file_paths: List[Path]) -> List[Path]:
        """ì…ë ¥ íŒŒì¼ ê²€ì¦"""
        valid_files = []
        
        for file_path in file_paths:
            if not file_path.exists():
                print(f"ê²½ê³ : íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
                continue
            
            if file_path.stat().st_size == 0:
                print(f"ê²½ê³ : ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤: {file_path}")
                continue
            
            valid_files.append(file_path)
        
        return valid_files
    
    @staticmethod
    def check_document_consistency(content: str) -> Dict[str, bool]:
        """ë¬¸ì„œ ì¼ê´€ì„± ê²€ì‚¬"""
        checks = {
            "has_content": len(content.strip()) > 0,
            "has_structure": any(keyword in content for keyword in ["ë¶€ë¬¸", "ì¥", "ì ˆ"]),
            "has_page_breaks": "===" in content,
            "encoding_valid": True
        }
        
        try:
            content.encode('utf-8')
        except UnicodeEncodeError:
            checks["encoding_valid"] = False
        
        return checks
    
    @staticmethod
    def generate_analysis_report(results: Dict[str, Any]) -> str:
        """ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        report = []
        report.append("=== ë¬¸ì„œ ë¶„ì„ ë³´ê³ ì„œ ===")
        
        # íŒŒì¼ ì •ë³´
        file_info = results.get("file_info", {})
        report.append(f"íŒŒì¼ëª…: {file_info.get('name', 'N/A')}")
        report.append(f"í¬ê¸°: {file_info.get('size', 0)} bytes")
        
        # êµ¬ì¡° ì •ë³´
        structure = results.get("structure", {})
        if structure.get("sections"):
            report.append("ë°œê²¬ëœ ë¶€ë¬¸:")
            for section, info in structure["sections"].items():
                if info.get("start") is not None:
                    report.append(f"  - {section}")
        
        # ê²€ì¦ ê²°ê³¼
        validation = results.get("validation", {})
        report.append("ê²€ì¦ ê²°ê³¼:")
        for check, status in validation.items():
            status_text = "âœ… í†µê³¼" if status else "âŒ ì‹¤íŒ¨"
            report.append(f"  - {check}: {status_text}")
        
        # ê¶Œì¥ì‚¬í•­
        recommendations = results.get("recommendations", [])
        if recommendations:
            report.append("ê¶Œì¥ì‚¬í•­:")
            for rec in recommendations:
                report.append(f"  - {rec}")
        
        return "\n".join(report)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # PDF íŒŒì¼ ê²½ë¡œ
    pdf_path = INPUT_DIR / "split_3_49.pdf"
    
    # í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° ìƒì„±
    extractor = PDFTextExtractor()
    
    # PDF ì •ë³´ ì¶œë ¥
    print("=== PDF íŒŒì¼ ì •ë³´ ===")
    info = extractor.get_pdf_info(pdf_path)
    for key, value in info.items():
        print(f"{key}: {value}")
    print()
    
    # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    print("=== ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ===")
    result_path = extractor.extract_text_by_pages(pdf_path)
    
    if result_path:
        print(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ: {result_path}")
    else:
        print("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")

if __name__ == "__main__":
    main() 