#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìƒˆë¡œ ì¶”ê°€ëœ ê²€ì¦ ê·œì¹™ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê±´ì¶•ë¶€ë¬¸ ëˆ„ë½ ì‚¬ê³  ë°©ì§€ë¥¼ ìœ„í•œ ê·œì¹™ë“¤ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

def pre_analysis_checklist(file_path: Path) -> Dict[str, bool]:
    """ë¶„ì„ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸ - ë°˜ë“œì‹œ ì‹¤í–‰"""
    checklist = {
        "file_exists": False,
        "file_readable": False,
        "file_not_empty": False,
        "encoding_supported": False,
        "content_contains_korean": False,
        "ready_for_analysis": False
    }
    
    try:
        # 1. íŒŒì¼ ì¡´ì¬ í™•ì¸
        if file_path.exists():
            checklist["file_exists"] = True
        
        # 2. íŒŒì¼ ì½ê¸° ê°€ëŠ¥ í™•ì¸
        if file_path.is_file():
            checklist["file_readable"] = True
        
        # 3. íŒŒì¼ í¬ê¸° í™•ì¸
        if file_path.stat().st_size > 0:
            checklist["file_not_empty"] = True
        
        # 4. ì¸ì½”ë”© ì§€ì› í™•ì¸
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read(1000)
                checklist["encoding_supported"] = True
                
                # 5. í•œêµ­ì–´ ë‚´ìš© í¬í•¨ í™•ì¸
                if any('\u3131' <= char <= '\u318E' or '\uAC00' <= char <= '\uD7A3' for char in content):
                    checklist["content_contains_korean"] = True
        except UnicodeDecodeError:
            pass
        
        # 6. ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ í™•ì¸
        checklist["ready_for_analysis"] = all([
            checklist["file_exists"],
            checklist["file_readable"],
            checklist["file_not_empty"],
            checklist["encoding_supported"],
            checklist["content_contains_korean"]
        ])
        
    except Exception as e:
        print(f"ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return checklist

def validate_all_sections(content: str) -> Dict[str, Any]:
    """ëª¨ë“  ë¶€ë¬¸ ê²€ì¦ - ë°˜ë“œì‹œ ì‹¤í–‰"""
    # ê³µë°±ì´ ìˆëŠ” í˜•íƒœì™€ ì—†ëŠ” í˜•íƒœ ëª¨ë‘ ê²€ìƒ‰
    required_sections = [
        "ê³µí†µë¶€ë¬¸", "ê³µ í†µ ë¶€ ë¬¸",
        "í† ëª©ë¶€ë¬¸", "í†  ëª© ë¶€ ë¬¸", 
        "ê±´ì¶•ë¶€ë¬¸", "ê±´ ì¶• ë¶€ ë¬¸",
        "ê¸°ê³„ì„¤ë¹„ë¶€ë¬¸", "ê¸° ê³„ ì„¤ ë¹„ ë¶€ ë¬¸",
        "ìœ ì§€ê´€ë¦¬ë¶€ë¬¸", "ìœ  ì§€ ê´€ ë¦¬ ë¶€ ë¬¸"
    ]
    
    validation_result = {
        "all_sections_found": True,
        "section_details": {},
        "missing_sections": [],
        "section_order": [],
        "validation_passed": False
    }
    
    # ê° ë¶€ë¬¸ ê²€ìƒ‰ ë° ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
    found_sections = []
    
    for section in required_sections:
        section_info = {
            "found": False,
            "position": -1,
            "line_number": -1,
            "context": "",
            "original_text": section
        }
        
        # ë¶€ë¬¸ ê²€ìƒ‰
        pos = content.find(section)
        if pos != -1:
            section_info["found"] = True
            section_info["position"] = pos
            
            # ì¤„ ë²ˆí˜¸ ê³„ì‚°
            lines_before = content[:pos].count('\n')
            section_info["line_number"] = lines_before + 1
            
            # ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì•ë’¤ 100ì)
            start = max(0, pos - 100)
            end = min(len(content), pos + len(section) + 100)
            section_info["context"] = content[start:end]
            
            # ë¶€ë¬¸ ì´ë¦„ ì •ê·œí™” (ê³µë°± ì œê±°)
            normalized_name = section.replace(" ", "")
            validation_result["section_details"][normalized_name] = section_info
            found_sections.append((normalized_name, pos))
    
    # í•„ìˆ˜ ë¶€ë¬¸ í™•ì¸ (ì •ê·œí™”ëœ ì´ë¦„ìœ¼ë¡œ)
    required_normalized = ["ê³µí†µë¶€ë¬¸", "í† ëª©ë¶€ë¬¸", "ê±´ì¶•ë¶€ë¬¸", "ê¸°ê³„ì„¤ë¹„ë¶€ë¬¸", "ìœ ì§€ê´€ë¦¬ë¶€ë¬¸"]
    found_normalized = [section for section, _ in found_sections]
    
    for section in required_normalized:
        if section not in found_normalized:
            validation_result["missing_sections"].append(section)
            validation_result["all_sections_found"] = False
    
    # ë¶€ë¬¸ ìˆœì„œ ê²°ì •
    found_sections.sort(key=lambda x: x[1])
    validation_result["section_order"] = [section for section, _ in found_sections]
    
    # ê²€ì¦ í†µê³¼ ì—¬ë¶€
    validation_result["validation_passed"] = validation_result["all_sections_found"]
    
    return validation_result

def generate_validated_analysis_report(file_path: Path, analysis_results: Dict[str, Any], 
                                     validation_results: Dict[str, Any]) -> str:
    """ê²€ì¦ëœ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± - ë°˜ë“œì‹œ ì‚¬ìš©"""
    
    # 1. ê¸°ë³¸ ë³´ê³ ì„œ ìƒì„±
    report = f"""# ğŸ“‹ PDF êµ¬ì¡° ë¶„ì„ ë³´ê³ ì„œ (ê²€ì¦ë¨)

## ğŸ¯ ë¶„ì„ ê°œìš”
- **íŒŒì¼ëª…**: {file_path.name}
- **ë¶„ì„ ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ê²€ì¦ ìƒíƒœ**: {'âœ… í†µê³¼' if validation_results.get('validation_passed', False) else 'âŒ ì‹¤íŒ¨'}

## ğŸ—ï¸ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„
"""
    
    # 2. ë¶€ë¬¸ë³„ ìƒì„¸ ì •ë³´ ì¶”ê°€
    section_details = validation_results.get("section_details", {})
    for section_name, section_info in section_details.items():
        if section_info["found"]:
            report += f"""
### {section_name}
- **ìœ„ì¹˜**: {section_info['line_number']}ë²ˆì§¸ ì¤„
- **ì»¨í…ìŠ¤íŠ¸**: {section_info['context'][:200]}...
"""
    
    # 3. ëˆ„ë½ëœ ë¶€ë¬¸ ê²½ê³ 
    missing_sections = validation_results.get("missing_sections", [])
    if missing_sections:
        report += f"""
## âš ï¸ ëˆ„ë½ëœ ë¶€ë¬¸
ë‹¤ìŒ ë¶€ë¬¸ì´ ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:
{chr(10).join(f'- {section}' for section in missing_sections)}

**ê¶Œì¥ì‚¬í•­**: ì „ì²´ ë¬¸ì„œë¥¼ ë‹¤ì‹œ ê²€í† í•˜ì—¬ ëˆ„ë½ëœ ë¶€ë¬¸ì„ í™•ì¸í•˜ì„¸ìš”.
"""
    
    # 4. ê²€ì¦ ê²°ê³¼ ìš”ì•½
    report += f"""
## âœ… ê²€ì¦ ê²°ê³¼
- **ëª¨ë“  ë¶€ë¬¸ ë°œê²¬**: {'ì˜ˆ' if validation_results.get('all_sections_found', False) else 'ì•„ë‹ˆì˜¤'}
- **ë¶€ë¬¸ ìˆœì„œ**: {' â†’ '.join(validation_results.get('section_order', []))}
- **ë¶„ì„ ì‹ ë¢°ë„**: {analysis_results.get('analysis_confidence', 0):.1f}%

## ğŸ’¡ ê¶Œì¥ì‚¬í•­
"""
    
    if validation_results.get("validation_passed", False):
        report += "- âœ… ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
    else:
        report += "- ğŸ”„ ëˆ„ë½ëœ ë¶€ë¬¸ì„ í™•ì¸í•˜ê³  ì¬ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.\n"
        report += "- ğŸ“– ë¬¸ì„œì˜ ì „ì²´ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ ê²€í† í•˜ì„¸ìš”.\n"
        report += "- ğŸ” ë¶€ë¬¸ ì œëª©ì˜ ì •í™•í•œ í‘œê¸°ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n"
    
    return report

def execute_error_prevention_workflow(file_path: Path) -> Dict[str, Any]:
    """ì˜¤ë¥˜ ë°©ì§€ ì›Œí¬í”Œë¡œìš° - ë°˜ë“œì‹œ ì‚¬ìš©"""
    try:
        # 1ë‹¨ê³„: ì‚¬ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸
        checklist = pre_analysis_checklist(file_path)
        if not checklist["ready_for_analysis"]:
            return {
                "error": "íŒŒì¼ì´ ë¶„ì„ ì¤€ë¹„ê°€ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                "checklist": checklist,
                "is_valid": False
            }
        
        # 2ë‹¨ê³„: íŒŒì¼ ë‚´ìš© ë¡œë“œ
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # 3ë‹¨ê³„: ë¶€ë¬¸ ê²€ì¦
        validation_results = validate_all_sections(content)
        
        # 4ë‹¨ê³„: ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰ (ê°„ë‹¨í•œ ë²„ì „)
        analysis_results = {
            "analysis_confidence": 85.0,
            "file_info": {
                "name": file_path.name,
                "size": file_path.stat().st_size
            }
        }
        
        # 5ë‹¨ê³„: ê²€ì¦ëœ ë³´ê³ ì„œ ìƒì„±
        comprehensive_report = generate_validated_analysis_report(
            file_path, analysis_results, validation_results
        )
        
        # 6ë‹¨ê³„: ê²°ê³¼ ë°˜í™˜
        final_result = {
            "checklist": checklist,
            "validation_results": validation_results,
            "analysis_results": analysis_results,
            "comprehensive_report": comprehensive_report,
            "is_valid": validation_results.get("validation_passed", False)
        }
        
        # 7ë‹¨ê³„: ê²€ì¦ ì‹¤íŒ¨ ì‹œ ê²½ê³ 
        if not final_result["is_valid"]:
            print("âš ï¸ ê²½ê³ : ë¶€ë¬¸ ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤!")
            print(f"ëˆ„ë½ëœ ë¶€ë¬¸: {', '.join(validation_results.get('missing_sections', []))}")
            print("ì „ì²´ ë¬¸ì„œë¥¼ ë‹¤ì‹œ ê²€í† í•˜ì„¸ìš”.")
        
        return final_result
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°©ì§€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {
            "error": str(e),
            "is_valid": False
        }

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ§ª ìƒˆë¡œ ì¶”ê°€ëœ ê²€ì¦ ê·œì¹™ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # í…ŒìŠ¤íŠ¸í•  íŒŒì¼ ê²½ë¡œ
    test_file = Path("output/split_3_49_extracted_20250620_165853.txt")
    
    if not test_file.exists():
        print(f"âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_file}")
        return
    
    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ íŒŒì¼: {test_file}")
    
    # ì˜¤ë¥˜ ë°©ì§€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    result = execute_error_prevention_workflow(test_file)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*50)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("="*50)
    
    if result.get("is_valid", False):
        print("âœ… ê²€ì¦ í†µê³¼: ëª¨ë“  ë¶€ë¬¸ì´ ì •ìƒì ìœ¼ë¡œ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âŒ ê²€ì¦ ì‹¤íŒ¨: ì¼ë¶€ ë¶€ë¬¸ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
    validation_results = result.get("validation_results", {})
    if validation_results.get("missing_sections"):
        print(f"ğŸ“‹ ëˆ„ë½ëœ ë¶€ë¬¸: {', '.join(validation_results['missing_sections'])}")
    
    if validation_results.get("section_order"):
        print(f"ğŸ“‹ ë°œê²¬ëœ ë¶€ë¬¸ ìˆœì„œ: {' â†’ '.join(validation_results['section_order'])}")
    
    # ë³´ê³ ì„œ ì €ì¥
    report_file = Path("output/validation_test_report.md")
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(result.get("comprehensive_report", ""))
    
    print(f"ğŸ“„ ìƒì„¸ ë³´ê³ ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {report_file}")
    
    print("\nğŸ¯ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 